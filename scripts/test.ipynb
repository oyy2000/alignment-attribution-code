{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "209b9681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated sys.path: ['/common/users/sl2148/Public/yang_ouyang/alignment-attribution-code/scripts', '/common/home/sl2148/anaconda3/envs/prune_llm/lib/python39.zip', '/common/home/sl2148/anaconda3/envs/prune_llm/lib/python3.9', '/common/home/sl2148/anaconda3/envs/prune_llm/lib/python3.9/lib-dynload', '', '/common/home/sl2148/anaconda3/envs/prune_llm/lib/python3.9/site-packages', '/common/users/sl2148/Public/yang_ouyang/alignment-attribution-code/']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# 设置你的 main.py 所在目录路径，例如：\n",
    "project_dir = \"/common/users/sl2148/Public/yang_ouyang/alignment-attribution-code/\"\n",
    "\n",
    "# 自动获取当前 Notebook 所在目录下的 \"src\" 或其他文件夹\n",
    "# project_dir = os.path.abspath(\"\")\n",
    "\n",
    "# 加入到 sys.path（如果尚未添加）\n",
    "if project_dir not in sys.path:\n",
    "    sys.path.append(project_dir)\n",
    "\n",
    "# 检查是否添加成功\n",
    "print(\"Updated sys.path:\", sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d22d23cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from lib.prune import (\n",
    "    prune_wanda,\n",
    "    check_sparsity,\n",
    "    get_mask,\n",
    ")\n",
    "from lib.eval import eval_ppl, eval_zero_shot, eval_attack\n",
    "from vllm import LLM\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bead353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📌 设置参数（你原本命令行中给出的内容）\n",
    "# 构造参数\n",
    "args = argparse.Namespace(\n",
    "    model=\"llama2-7b-chat-hf\",\n",
    "    model_base=\"llama2-7b-hf\",\n",
    "    seed=0,\n",
    "    nsamples=128,\n",
    "    sparsity_ratio=0.5,\n",
    "    sparsity_type=\"unstructured\",\n",
    "    prune_method=\"wanda\",  # 举例使用 wanda\n",
    "    prune_data=\"alpaca_cleaned_no_safety\",\n",
    "    use_diff=False,\n",
    "    neg_prune=False,\n",
    "    recover_from_base=False,\n",
    "    p=0.5,\n",
    "    q=0.5,\n",
    "    top_k_heads=10,\n",
    "    cache_dir=\"llm_weights\",\n",
    "    use_variant=False,\n",
    "    save=None,\n",
    "    save_model=None,\n",
    "    save_mask=None,\n",
    "    dump_wanda_score=False,\n",
    "    eval_zero_shot=False,\n",
    "    eval_attack=False,\n",
    "    save_attack_res=False,\n",
    "    prune_part=False,\n",
    "    disentangle=True,  # 注意：原 argparse 中是 --entangle_prompt_feat -> dest=\"disentangle\", action=\"store_false\"\n",
    "    decouple_align_utility=False,\n",
    "    decouple_align_misalign=False,\n",
    "    rank=10,\n",
    "    niter=20,\n",
    ")\n",
    "model_name = \"llama2-7b-chat-hf\"\n",
    "model_base = \"llama2-7b-hf\"\n",
    "prune_method = \"wanda\"\n",
    "sparsity_ratio = 0.5\n",
    "sparsity_type = \"unstructured\"\n",
    "prune_data = \"align\"\n",
    "neg_prune = True\n",
    "save_attack_res = True\n",
    "eval_zero_shot = True\n",
    "eval_attack = True\n",
    "suffix = \"weightonly\"\n",
    "cache_dir = \"llm_weights\"\n",
    "save_dir = f\"out/{model_name}/{sparsity_type}/{prune_method}_{suffix}/{prune_data}\"\n",
    "os.makedirs(save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c838259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90b5035a0048426f8bc3c54d090aaf85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 💾 模型路径映射\n",
    "modeltype2path = {\n",
    "    \"llama2-7b-chat-hf\": \"meta-llama/Llama-2-7b-chat-hf\",\n",
    "    \"llama2-7b-hf\": \"meta-llama/Llama-2-7b-hf\",\n",
    "}\n",
    "\n",
    "# ✅ 加载模型和 tokenizer\n",
    "def get_llm(model_name, cache_dir):\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        modeltype2path[model_name],\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        cache_dir=cache_dir,\n",
    "        low_cpu_mem_usage=True,\n",
    "        device_map=\"auto\",\n",
    "        token=os.environ.get(\"HF_TOKEN\"),\n",
    "    )\n",
    "    model.seqlen = model.config.max_position_embeddings\n",
    "    return model\n",
    "\n",
    "model = get_llm(model_name, cache_dir)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad6253d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "开始剪枝： wanda\n",
      "loading calibration data alpaca_cleaned_no_safety\n",
      "dataset loading complete\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([29, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([144, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([349, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([42, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([691, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([489, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([85, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([240, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([67, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([90, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([328, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([68, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([298, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([260, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([43, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([235, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([377, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([263, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([375, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([50, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([96, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([39, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([49, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([160, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([165, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([225, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([91, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([431, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([294, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([401, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([298, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([46, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([426, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([377, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([185, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([40, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([380, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([54, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([368, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([190, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([91, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([93, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([27, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([104, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([204, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([168, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([90, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([270, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([48, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([50, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([222, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([282, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([633, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([397, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([138, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([159, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([41, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([38, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([35, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([149, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([61, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([345, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([100, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([193, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([76, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([44, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([424, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([239, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([36, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([82, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([35, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([94, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([367, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([116, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([42, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([105, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([90, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([62, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([27, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([85, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([131, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([166, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([421, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([129, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([400, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([51, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([49, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([138, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([538, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([105, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([172, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([408, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([332, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([47, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([54, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([28, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([107, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([185, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([412, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([80, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([52, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([479, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([49, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([51, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([423, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([437, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([148, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([99, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([19, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([33, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([60, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([89, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([441, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([169, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([382, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([60, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([261, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([141, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([279, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([211, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([229, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([42, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([201, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([131, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([71, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([95, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([41, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([307, 4096])\n",
      "prune every linear layer\n",
      "pruning layer 0 name self_attn.q_proj\n",
      "pruning layer 0 name self_attn.k_proj\n",
      "pruning layer 0 name self_attn.v_proj\n",
      "pruning layer 0 name self_attn.o_proj\n",
      "pruning layer 0 name mlp.gate_proj\n",
      "pruning layer 0 name mlp.up_proj\n",
      "pruning layer 0 name mlp.down_proj\n",
      "pruning layer 1 name self_attn.q_proj\n",
      "pruning layer 1 name self_attn.k_proj\n",
      "pruning layer 1 name self_attn.v_proj\n",
      "pruning layer 1 name self_attn.o_proj\n",
      "pruning layer 1 name mlp.gate_proj\n",
      "pruning layer 1 name mlp.up_proj\n",
      "pruning layer 1 name mlp.down_proj\n",
      "pruning layer 2 name self_attn.q_proj\n",
      "pruning layer 2 name self_attn.k_proj\n",
      "pruning layer 2 name self_attn.v_proj\n",
      "pruning layer 2 name self_attn.o_proj\n",
      "pruning layer 2 name mlp.gate_proj\n",
      "pruning layer 2 name mlp.up_proj\n",
      "pruning layer 2 name mlp.down_proj\n",
      "pruning layer 3 name self_attn.q_proj\n",
      "pruning layer 3 name self_attn.k_proj\n",
      "pruning layer 3 name self_attn.v_proj\n",
      "pruning layer 3 name self_attn.o_proj\n",
      "pruning layer 3 name mlp.gate_proj\n",
      "pruning layer 3 name mlp.up_proj\n",
      "pruning layer 3 name mlp.down_proj\n",
      "pruning layer 4 name self_attn.q_proj\n",
      "pruning layer 4 name self_attn.k_proj\n",
      "pruning layer 4 name self_attn.v_proj\n",
      "pruning layer 4 name self_attn.o_proj\n",
      "pruning layer 4 name mlp.gate_proj\n",
      "pruning layer 4 name mlp.up_proj\n",
      "pruning layer 4 name mlp.down_proj\n",
      "pruning layer 5 name self_attn.q_proj\n",
      "pruning layer 5 name self_attn.k_proj\n",
      "pruning layer 5 name self_attn.v_proj\n",
      "pruning layer 5 name self_attn.o_proj\n",
      "pruning layer 5 name mlp.gate_proj\n",
      "pruning layer 5 name mlp.up_proj\n",
      "pruning layer 5 name mlp.down_proj\n",
      "pruning layer 6 name self_attn.q_proj\n",
      "pruning layer 6 name self_attn.k_proj\n",
      "pruning layer 6 name self_attn.v_proj\n",
      "pruning layer 6 name self_attn.o_proj\n",
      "pruning layer 6 name mlp.gate_proj\n",
      "pruning layer 6 name mlp.up_proj\n",
      "pruning layer 6 name mlp.down_proj\n",
      "pruning layer 7 name self_attn.q_proj\n",
      "pruning layer 7 name self_attn.k_proj\n",
      "pruning layer 7 name self_attn.v_proj\n",
      "pruning layer 7 name self_attn.o_proj\n",
      "pruning layer 7 name mlp.gate_proj\n",
      "pruning layer 7 name mlp.up_proj\n",
      "pruning layer 7 name mlp.down_proj\n",
      "pruning layer 8 name self_attn.q_proj\n",
      "pruning layer 8 name self_attn.k_proj\n",
      "pruning layer 8 name self_attn.v_proj\n",
      "pruning layer 8 name self_attn.o_proj\n",
      "pruning layer 8 name mlp.gate_proj\n",
      "pruning layer 8 name mlp.up_proj\n",
      "pruning layer 8 name mlp.down_proj\n",
      "pruning layer 9 name self_attn.q_proj\n",
      "pruning layer 9 name self_attn.k_proj\n",
      "pruning layer 9 name self_attn.v_proj\n",
      "pruning layer 9 name self_attn.o_proj\n",
      "pruning layer 9 name mlp.gate_proj\n",
      "pruning layer 9 name mlp.up_proj\n",
      "pruning layer 9 name mlp.down_proj\n",
      "pruning layer 10 name self_attn.q_proj\n",
      "pruning layer 10 name self_attn.k_proj\n",
      "pruning layer 10 name self_attn.v_proj\n",
      "pruning layer 10 name self_attn.o_proj\n",
      "pruning layer 10 name mlp.gate_proj\n",
      "pruning layer 10 name mlp.up_proj\n",
      "pruning layer 10 name mlp.down_proj\n",
      "pruning layer 11 name self_attn.q_proj\n",
      "pruning layer 11 name self_attn.k_proj\n",
      "pruning layer 11 name self_attn.v_proj\n",
      "pruning layer 11 name self_attn.o_proj\n",
      "pruning layer 11 name mlp.gate_proj\n",
      "pruning layer 11 name mlp.up_proj\n",
      "pruning layer 11 name mlp.down_proj\n",
      "pruning layer 12 name self_attn.q_proj\n",
      "pruning layer 12 name self_attn.k_proj\n",
      "pruning layer 12 name self_attn.v_proj\n",
      "pruning layer 12 name self_attn.o_proj\n",
      "pruning layer 12 name mlp.gate_proj\n",
      "pruning layer 12 name mlp.up_proj\n",
      "pruning layer 12 name mlp.down_proj\n",
      "pruning layer 13 name self_attn.q_proj\n",
      "pruning layer 13 name self_attn.k_proj\n",
      "pruning layer 13 name self_attn.v_proj\n",
      "pruning layer 13 name self_attn.o_proj\n",
      "pruning layer 13 name mlp.gate_proj\n",
      "pruning layer 13 name mlp.up_proj\n",
      "pruning layer 13 name mlp.down_proj\n",
      "pruning layer 14 name self_attn.q_proj\n",
      "pruning layer 14 name self_attn.k_proj\n",
      "pruning layer 14 name self_attn.v_proj\n",
      "pruning layer 14 name self_attn.o_proj\n",
      "pruning layer 14 name mlp.gate_proj\n",
      "pruning layer 14 name mlp.up_proj\n",
      "pruning layer 14 name mlp.down_proj\n",
      "pruning layer 15 name self_attn.q_proj\n",
      "pruning layer 15 name self_attn.k_proj\n",
      "pruning layer 15 name self_attn.v_proj\n",
      "pruning layer 15 name self_attn.o_proj\n",
      "pruning layer 15 name mlp.gate_proj\n",
      "pruning layer 15 name mlp.up_proj\n",
      "pruning layer 15 name mlp.down_proj\n",
      "pruning layer 16 name self_attn.q_proj\n",
      "pruning layer 16 name self_attn.k_proj\n",
      "pruning layer 16 name self_attn.v_proj\n",
      "pruning layer 16 name self_attn.o_proj\n",
      "pruning layer 16 name mlp.gate_proj\n",
      "pruning layer 16 name mlp.up_proj\n",
      "pruning layer 16 name mlp.down_proj\n",
      "pruning layer 17 name self_attn.q_proj\n",
      "pruning layer 17 name self_attn.k_proj\n",
      "pruning layer 17 name self_attn.v_proj\n",
      "pruning layer 17 name self_attn.o_proj\n",
      "pruning layer 17 name mlp.gate_proj\n",
      "pruning layer 17 name mlp.up_proj\n",
      "pruning layer 17 name mlp.down_proj\n",
      "pruning layer 18 name self_attn.q_proj\n",
      "pruning layer 18 name self_attn.k_proj\n",
      "pruning layer 18 name self_attn.v_proj\n",
      "pruning layer 18 name self_attn.o_proj\n",
      "pruning layer 18 name mlp.gate_proj\n",
      "pruning layer 18 name mlp.up_proj\n",
      "pruning layer 18 name mlp.down_proj\n",
      "pruning layer 19 name self_attn.q_proj\n",
      "pruning layer 19 name self_attn.k_proj\n",
      "pruning layer 19 name self_attn.v_proj\n",
      "pruning layer 19 name self_attn.o_proj\n",
      "pruning layer 19 name mlp.gate_proj\n",
      "pruning layer 19 name mlp.up_proj\n",
      "pruning layer 19 name mlp.down_proj\n",
      "pruning layer 20 name self_attn.q_proj\n",
      "pruning layer 20 name self_attn.k_proj\n",
      "pruning layer 20 name self_attn.v_proj\n",
      "pruning layer 20 name self_attn.o_proj\n",
      "pruning layer 20 name mlp.gate_proj\n",
      "pruning layer 20 name mlp.up_proj\n",
      "pruning layer 20 name mlp.down_proj\n",
      "pruning layer 21 name self_attn.q_proj\n",
      "pruning layer 21 name self_attn.k_proj\n",
      "pruning layer 21 name self_attn.v_proj\n",
      "pruning layer 21 name self_attn.o_proj\n",
      "pruning layer 21 name mlp.gate_proj\n",
      "pruning layer 21 name mlp.up_proj\n",
      "pruning layer 21 name mlp.down_proj\n",
      "pruning layer 22 name self_attn.q_proj\n",
      "pruning layer 22 name self_attn.k_proj\n",
      "pruning layer 22 name self_attn.v_proj\n",
      "pruning layer 22 name self_attn.o_proj\n",
      "pruning layer 22 name mlp.gate_proj\n",
      "pruning layer 22 name mlp.up_proj\n",
      "pruning layer 22 name mlp.down_proj\n",
      "pruning layer 23 name self_attn.q_proj\n",
      "pruning layer 23 name self_attn.k_proj\n",
      "pruning layer 23 name self_attn.v_proj\n",
      "pruning layer 23 name self_attn.o_proj\n",
      "pruning layer 23 name mlp.gate_proj\n",
      "pruning layer 23 name mlp.up_proj\n",
      "pruning layer 23 name mlp.down_proj\n",
      "pruning layer 24 name self_attn.q_proj\n",
      "pruning layer 24 name self_attn.k_proj\n",
      "pruning layer 24 name self_attn.v_proj\n",
      "pruning layer 24 name self_attn.o_proj\n",
      "pruning layer 24 name mlp.gate_proj\n",
      "pruning layer 24 name mlp.up_proj\n",
      "pruning layer 24 name mlp.down_proj\n",
      "pruning layer 25 name self_attn.q_proj\n",
      "pruning layer 25 name self_attn.k_proj\n",
      "pruning layer 25 name self_attn.v_proj\n",
      "pruning layer 25 name self_attn.o_proj\n",
      "pruning layer 25 name mlp.gate_proj\n",
      "pruning layer 25 name mlp.up_proj\n",
      "pruning layer 25 name mlp.down_proj\n",
      "pruning layer 26 name self_attn.q_proj\n",
      "pruning layer 26 name self_attn.k_proj\n",
      "pruning layer 26 name self_attn.v_proj\n",
      "pruning layer 26 name self_attn.o_proj\n",
      "pruning layer 26 name mlp.gate_proj\n",
      "pruning layer 26 name mlp.up_proj\n",
      "pruning layer 26 name mlp.down_proj\n",
      "pruning layer 27 name self_attn.q_proj\n",
      "pruning layer 27 name self_attn.k_proj\n",
      "pruning layer 27 name self_attn.v_proj\n",
      "pruning layer 27 name self_attn.o_proj\n",
      "pruning layer 27 name mlp.gate_proj\n",
      "pruning layer 27 name mlp.up_proj\n",
      "pruning layer 27 name mlp.down_proj\n",
      "pruning layer 28 name self_attn.q_proj\n",
      "pruning layer 28 name self_attn.k_proj\n",
      "pruning layer 28 name self_attn.v_proj\n",
      "pruning layer 28 name self_attn.o_proj\n",
      "pruning layer 28 name mlp.gate_proj\n",
      "pruning layer 28 name mlp.up_proj\n",
      "pruning layer 28 name mlp.down_proj\n",
      "pruning layer 29 name self_attn.q_proj\n",
      "pruning layer 29 name self_attn.k_proj\n",
      "pruning layer 29 name self_attn.v_proj\n",
      "pruning layer 29 name self_attn.o_proj\n",
      "pruning layer 29 name mlp.gate_proj\n",
      "pruning layer 29 name mlp.up_proj\n",
      "pruning layer 29 name mlp.down_proj\n",
      "pruning layer 30 name self_attn.q_proj\n",
      "pruning layer 30 name self_attn.k_proj\n",
      "pruning layer 30 name self_attn.v_proj\n",
      "pruning layer 30 name self_attn.o_proj\n",
      "pruning layer 30 name mlp.gate_proj\n",
      "pruning layer 30 name mlp.up_proj\n",
      "pruning layer 30 name mlp.down_proj\n",
      "pruning layer 31 name self_attn.q_proj\n",
      "pruning layer 31 name self_attn.k_proj\n",
      "pruning layer 31 name self_attn.v_proj\n",
      "pruning layer 31 name self_attn.o_proj\n",
      "pruning layer 31 name mlp.gate_proj\n",
      "pruning layer 31 name mlp.up_proj\n",
      "pruning layer 31 name mlp.down_proj\n",
      "layer 0 sparsity 0.500000\n",
      "layer 1 sparsity 0.500000\n",
      "layer 2 sparsity 0.500000\n",
      "layer 3 sparsity 0.500000\n",
      "layer 4 sparsity 0.500000\n",
      "layer 5 sparsity 0.500000\n",
      "layer 6 sparsity 0.500000\n",
      "layer 7 sparsity 0.500000\n",
      "layer 8 sparsity 0.500000\n",
      "layer 9 sparsity 0.500000\n",
      "layer 10 sparsity 0.500000\n",
      "layer 11 sparsity 0.500000\n",
      "layer 12 sparsity 0.500000\n",
      "layer 13 sparsity 0.500000\n",
      "layer 14 sparsity 0.500000\n",
      "layer 15 sparsity 0.500000\n",
      "layer 16 sparsity 0.500000\n",
      "layer 17 sparsity 0.500000\n",
      "layer 18 sparsity 0.500000\n",
      "layer 19 sparsity 0.500000\n",
      "layer 20 sparsity 0.500000\n",
      "layer 21 sparsity 0.500000\n",
      "layer 22 sparsity 0.500000\n",
      "layer 23 sparsity 0.500000\n",
      "layer 24 sparsity 0.500000\n",
      "layer 25 sparsity 0.500000\n",
      "layer 26 sparsity 0.500000\n",
      "layer 27 sparsity 0.500000\n",
      "layer 28 sparsity 0.500000\n",
      "layer 29 sparsity 0.500000\n",
      "layer 30 sparsity 0.500000\n",
      "layer 31 sparsity 0.500000\n",
      "实际 sparsity: 0.500000\n",
      "evaluating on wikitext\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aec409326304a6386fac16386533284",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae6e4bcc4d2543229c0e5bec92fa7da7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94e651c6c0d54e168d6238f2618e0294",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/733k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dd484fa95d44c549754d9072590c6c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/6.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35e4dfc96ca34afb9674789f75c4228b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/657k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "701834ada6824f9d8ee645975713e285",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "994d2ba897df4398bd7b1271c0982740",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/4358 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cc2450a8e044f82a49368f044fa6401",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/36718 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1cad852f667486a963203093b377d42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/3760 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nsamples 83\n",
      "sample 0\n",
      "sample 50\n",
      "Perplexity (Wikitext): 8.0701\n"
     ]
    }
   ],
   "source": [
    "# tokenizer\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    modeltype2path[model_name],\n",
    "    use_fast=False,\n",
    "    cache_dir=cache_dir,\n",
    ")\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({\"pad_token\": \"[PAD]\"})\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# ✅ Pruning (仅 unstructured 的 wanda 方法)\n",
    "prune_n, prune_m = 0, 0\n",
    "print(\"开始剪枝：\", prune_method)\n",
    "prune_wanda(\n",
    "    args=args,  # 不用 args\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    model_base=model_base,  \n",
    "    device=device,\n",
    "    prune_n=prune_n,\n",
    "    prune_m=prune_m,\n",
    "    prune_data=args.prune_data,\n",
    ")\n",
    "\n",
    "# ✅ Sparsity 检查\n",
    "sparsity_ratio_actual = check_sparsity(model)\n",
    "print(f\"实际 sparsity: {sparsity_ratio_actual:.6f}\")\n",
    "\n",
    "# ✅ PPL 评估\n",
    "ppl = eval_ppl(\n",
    "    args=None,\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    device=device,\n",
    ")\n",
    "print(f\"Perplexity (Wikitext): {ppl:.4f}\")\n",
    "\n",
    "# ✅ 选择性保存 mask（可选）\n",
    "save_mask_flag = False\n",
    "if save_mask_flag:\n",
    "    mask = get_mask(model, neg_prune)\n",
    "    mask_dir = os.path.join(save_dir, \"FT_mask\")\n",
    "    os.makedirs(mask_dir, exist_ok=True)\n",
    "    mask_path = os.path.join(mask_dir, f\"mask_bottom_{sparsity_ratio:.3f}.pt\")\n",
    "    torch.save(mask, mask_path)\n",
    "    print(f\"Mask 已保存: {mask_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ec4dd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prune_llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
