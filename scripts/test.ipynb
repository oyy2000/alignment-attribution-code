{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "209b9681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated sys.path: ['/common/users/sl2148/Public/yang_ouyang/alignment-attribution-code/scripts', '/common/home/sl2148/anaconda3/envs/prune_llm/lib/python39.zip', '/common/home/sl2148/anaconda3/envs/prune_llm/lib/python3.9', '/common/home/sl2148/anaconda3/envs/prune_llm/lib/python3.9/lib-dynload', '', '/common/home/sl2148/anaconda3/envs/prune_llm/lib/python3.9/site-packages', '/common/users/sl2148/Public/yang_ouyang/alignment-attribution-code/']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# è®¾ç½®ä½ çš„ main.py æ‰€åœ¨ç›®å½•è·¯å¾„ï¼Œä¾‹å¦‚ï¼š\n",
    "project_dir = \"/common/users/sl2148/Public/yang_ouyang/alignment-attribution-code/\"\n",
    "\n",
    "# è‡ªåŠ¨èŽ·å–å½“å‰ Notebook æ‰€åœ¨ç›®å½•ä¸‹çš„ \"src\" æˆ–å…¶ä»–æ–‡ä»¶å¤¹\n",
    "# project_dir = os.path.abspath(\"\")\n",
    "\n",
    "# åŠ å…¥åˆ° sys.pathï¼ˆå¦‚æžœå°šæœªæ·»åŠ ï¼‰\n",
    "if project_dir not in sys.path:\n",
    "    sys.path.append(project_dir)\n",
    "\n",
    "# æ£€æŸ¥æ˜¯å¦æ·»åŠ æˆåŠŸ\n",
    "print(\"Updated sys.path:\", sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d22d23cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from lib.prune import (\n",
    "    prune_wanda,\n",
    "    check_sparsity,\n",
    "    get_mask,\n",
    ")\n",
    "from lib.eval import eval_ppl, eval_zero_shot, eval_attack\n",
    "from vllm import LLM\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bead353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“Œ è®¾ç½®å‚æ•°ï¼ˆä½ åŽŸæœ¬å‘½ä»¤è¡Œä¸­ç»™å‡ºçš„å†…å®¹ï¼‰\n",
    "# æž„é€ å‚æ•°\n",
    "args = argparse.Namespace(\n",
    "    model=\"llama2-7b-chat-hf\",\n",
    "    model_base=\"llama2-7b-hf\",\n",
    "    seed=0,\n",
    "    nsamples=128,\n",
    "    sparsity_ratio=0.5,\n",
    "    sparsity_type=\"unstructured\",\n",
    "    prune_method=\"wanda\",  # ä¸¾ä¾‹ä½¿ç”¨ wanda\n",
    "    prune_data=\"alpaca_cleaned_no_safety\",\n",
    "    use_diff=False,\n",
    "    neg_prune=False,\n",
    "    recover_from_base=False,\n",
    "    p=0.5,\n",
    "    q=0.5,\n",
    "    top_k_heads=10,\n",
    "    cache_dir=\"llm_weights\",\n",
    "    use_variant=False,\n",
    "    save=None,\n",
    "    save_model=None,\n",
    "    save_mask=None,\n",
    "    dump_wanda_score=False,\n",
    "    eval_zero_shot=False,\n",
    "    eval_attack=False,\n",
    "    save_attack_res=False,\n",
    "    prune_part=False,\n",
    "    disentangle=True,  # æ³¨æ„ï¼šåŽŸ argparse ä¸­æ˜¯ --entangle_prompt_feat -> dest=\"disentangle\", action=\"store_false\"\n",
    "    decouple_align_utility=False,\n",
    "    decouple_align_misalign=False,\n",
    "    rank=10,\n",
    "    niter=20,\n",
    ")\n",
    "model_name = \"llama2-7b-chat-hf\"\n",
    "model_base = \"llama2-7b-hf\"\n",
    "prune_method = \"wanda\"\n",
    "sparsity_ratio = 0.5\n",
    "sparsity_type = \"unstructured\"\n",
    "prune_data = \"align\"\n",
    "neg_prune = True\n",
    "save_attack_res = True\n",
    "eval_zero_shot = True\n",
    "eval_attack = True\n",
    "suffix = \"weightonly\"\n",
    "cache_dir = \"llm_weights\"\n",
    "save_dir = f\"out/{model_name}/{sparsity_type}/{prune_method}_{suffix}/{prune_data}\"\n",
    "os.makedirs(save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c838259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90b5035a0048426f8bc3c54d090aaf85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ðŸ’¾ æ¨¡åž‹è·¯å¾„æ˜ å°„\n",
    "modeltype2path = {\n",
    "    \"llama2-7b-chat-hf\": \"meta-llama/Llama-2-7b-chat-hf\",\n",
    "    \"llama2-7b-hf\": \"meta-llama/Llama-2-7b-hf\",\n",
    "}\n",
    "\n",
    "# âœ… åŠ è½½æ¨¡åž‹å’Œ tokenizer\n",
    "def get_llm(model_name, cache_dir):\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        modeltype2path[model_name],\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        cache_dir=cache_dir,\n",
    "        low_cpu_mem_usage=True,\n",
    "        device_map=\"auto\",\n",
    "        token=os.environ.get(\"HF_TOKEN\"),\n",
    "    )\n",
    "    model.seqlen = model.config.max_position_embeddings\n",
    "    return model\n",
    "\n",
    "model = get_llm(model_name, cache_dir)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad6253d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "å¼€å§‹å‰ªæžï¼š wanda\n",
      "loading calibration data alpaca_cleaned_no_safety\n",
      "dataset loading complete\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([29, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([144, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([349, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([42, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([691, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([489, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([85, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([240, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([67, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([90, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([328, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([68, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([298, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([260, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([43, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([235, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([377, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([263, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([375, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([50, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([96, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([39, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([49, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([160, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([165, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([225, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([91, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([431, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([294, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([401, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([298, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([46, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([426, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([377, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([185, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([40, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([380, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([54, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([368, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([190, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([91, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([93, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([27, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([104, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([204, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([168, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([90, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([270, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([48, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([50, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([222, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([282, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([633, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([397, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([138, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([159, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([41, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([38, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([35, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([149, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([61, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([345, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([100, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([193, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([76, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([44, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([424, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([239, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([36, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([82, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([35, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([94, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([367, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([116, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([42, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([105, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([90, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([62, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([27, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([85, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([131, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([166, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([421, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([129, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([400, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([51, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([49, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([138, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([538, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([105, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([172, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([408, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([332, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([47, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([54, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([28, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([107, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([185, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([412, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([80, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([52, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([479, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([49, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([51, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([423, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([437, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([148, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([99, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([19, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([33, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([60, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([89, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([441, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([169, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([382, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([60, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([261, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([141, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([279, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([211, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([229, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([42, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([201, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([131, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([71, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([95, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([41, 4096])\n",
      "[DEBUG] inp type: <class 'torch.Tensor'>, len: 1, first shape: torch.Size([307, 4096])\n",
      "prune every linear layer\n",
      "pruning layer 0 name self_attn.q_proj\n",
      "pruning layer 0 name self_attn.k_proj\n",
      "pruning layer 0 name self_attn.v_proj\n",
      "pruning layer 0 name self_attn.o_proj\n",
      "pruning layer 0 name mlp.gate_proj\n",
      "pruning layer 0 name mlp.up_proj\n",
      "pruning layer 0 name mlp.down_proj\n",
      "pruning layer 1 name self_attn.q_proj\n",
      "pruning layer 1 name self_attn.k_proj\n",
      "pruning layer 1 name self_attn.v_proj\n",
      "pruning layer 1 name self_attn.o_proj\n",
      "pruning layer 1 name mlp.gate_proj\n",
      "pruning layer 1 name mlp.up_proj\n",
      "pruning layer 1 name mlp.down_proj\n",
      "pruning layer 2 name self_attn.q_proj\n",
      "pruning layer 2 name self_attn.k_proj\n",
      "pruning layer 2 name self_attn.v_proj\n",
      "pruning layer 2 name self_attn.o_proj\n",
      "pruning layer 2 name mlp.gate_proj\n",
      "pruning layer 2 name mlp.up_proj\n",
      "pruning layer 2 name mlp.down_proj\n",
      "pruning layer 3 name self_attn.q_proj\n",
      "pruning layer 3 name self_attn.k_proj\n",
      "pruning layer 3 name self_attn.v_proj\n",
      "pruning layer 3 name self_attn.o_proj\n",
      "pruning layer 3 name mlp.gate_proj\n",
      "pruning layer 3 name mlp.up_proj\n",
      "pruning layer 3 name mlp.down_proj\n",
      "pruning layer 4 name self_attn.q_proj\n",
      "pruning layer 4 name self_attn.k_proj\n",
      "pruning layer 4 name self_attn.v_proj\n",
      "pruning layer 4 name self_attn.o_proj\n",
      "pruning layer 4 name mlp.gate_proj\n",
      "pruning layer 4 name mlp.up_proj\n",
      "pruning layer 4 name mlp.down_proj\n",
      "pruning layer 5 name self_attn.q_proj\n",
      "pruning layer 5 name self_attn.k_proj\n",
      "pruning layer 5 name self_attn.v_proj\n",
      "pruning layer 5 name self_attn.o_proj\n",
      "pruning layer 5 name mlp.gate_proj\n",
      "pruning layer 5 name mlp.up_proj\n",
      "pruning layer 5 name mlp.down_proj\n",
      "pruning layer 6 name self_attn.q_proj\n",
      "pruning layer 6 name self_attn.k_proj\n",
      "pruning layer 6 name self_attn.v_proj\n",
      "pruning layer 6 name self_attn.o_proj\n",
      "pruning layer 6 name mlp.gate_proj\n",
      "pruning layer 6 name mlp.up_proj\n",
      "pruning layer 6 name mlp.down_proj\n",
      "pruning layer 7 name self_attn.q_proj\n",
      "pruning layer 7 name self_attn.k_proj\n",
      "pruning layer 7 name self_attn.v_proj\n",
      "pruning layer 7 name self_attn.o_proj\n",
      "pruning layer 7 name mlp.gate_proj\n",
      "pruning layer 7 name mlp.up_proj\n",
      "pruning layer 7 name mlp.down_proj\n",
      "pruning layer 8 name self_attn.q_proj\n",
      "pruning layer 8 name self_attn.k_proj\n",
      "pruning layer 8 name self_attn.v_proj\n",
      "pruning layer 8 name self_attn.o_proj\n",
      "pruning layer 8 name mlp.gate_proj\n",
      "pruning layer 8 name mlp.up_proj\n",
      "pruning layer 8 name mlp.down_proj\n",
      "pruning layer 9 name self_attn.q_proj\n",
      "pruning layer 9 name self_attn.k_proj\n",
      "pruning layer 9 name self_attn.v_proj\n",
      "pruning layer 9 name self_attn.o_proj\n",
      "pruning layer 9 name mlp.gate_proj\n",
      "pruning layer 9 name mlp.up_proj\n",
      "pruning layer 9 name mlp.down_proj\n",
      "pruning layer 10 name self_attn.q_proj\n",
      "pruning layer 10 name self_attn.k_proj\n",
      "pruning layer 10 name self_attn.v_proj\n",
      "pruning layer 10 name self_attn.o_proj\n",
      "pruning layer 10 name mlp.gate_proj\n",
      "pruning layer 10 name mlp.up_proj\n",
      "pruning layer 10 name mlp.down_proj\n",
      "pruning layer 11 name self_attn.q_proj\n",
      "pruning layer 11 name self_attn.k_proj\n",
      "pruning layer 11 name self_attn.v_proj\n",
      "pruning layer 11 name self_attn.o_proj\n",
      "pruning layer 11 name mlp.gate_proj\n",
      "pruning layer 11 name mlp.up_proj\n",
      "pruning layer 11 name mlp.down_proj\n",
      "pruning layer 12 name self_attn.q_proj\n",
      "pruning layer 12 name self_attn.k_proj\n",
      "pruning layer 12 name self_attn.v_proj\n",
      "pruning layer 12 name self_attn.o_proj\n",
      "pruning layer 12 name mlp.gate_proj\n",
      "pruning layer 12 name mlp.up_proj\n",
      "pruning layer 12 name mlp.down_proj\n",
      "pruning layer 13 name self_attn.q_proj\n",
      "pruning layer 13 name self_attn.k_proj\n",
      "pruning layer 13 name self_attn.v_proj\n",
      "pruning layer 13 name self_attn.o_proj\n",
      "pruning layer 13 name mlp.gate_proj\n",
      "pruning layer 13 name mlp.up_proj\n",
      "pruning layer 13 name mlp.down_proj\n",
      "pruning layer 14 name self_attn.q_proj\n",
      "pruning layer 14 name self_attn.k_proj\n",
      "pruning layer 14 name self_attn.v_proj\n",
      "pruning layer 14 name self_attn.o_proj\n",
      "pruning layer 14 name mlp.gate_proj\n",
      "pruning layer 14 name mlp.up_proj\n",
      "pruning layer 14 name mlp.down_proj\n",
      "pruning layer 15 name self_attn.q_proj\n",
      "pruning layer 15 name self_attn.k_proj\n",
      "pruning layer 15 name self_attn.v_proj\n",
      "pruning layer 15 name self_attn.o_proj\n",
      "pruning layer 15 name mlp.gate_proj\n",
      "pruning layer 15 name mlp.up_proj\n",
      "pruning layer 15 name mlp.down_proj\n",
      "pruning layer 16 name self_attn.q_proj\n",
      "pruning layer 16 name self_attn.k_proj\n",
      "pruning layer 16 name self_attn.v_proj\n",
      "pruning layer 16 name self_attn.o_proj\n",
      "pruning layer 16 name mlp.gate_proj\n",
      "pruning layer 16 name mlp.up_proj\n",
      "pruning layer 16 name mlp.down_proj\n",
      "pruning layer 17 name self_attn.q_proj\n",
      "pruning layer 17 name self_attn.k_proj\n",
      "pruning layer 17 name self_attn.v_proj\n",
      "pruning layer 17 name self_attn.o_proj\n",
      "pruning layer 17 name mlp.gate_proj\n",
      "pruning layer 17 name mlp.up_proj\n",
      "pruning layer 17 name mlp.down_proj\n",
      "pruning layer 18 name self_attn.q_proj\n",
      "pruning layer 18 name self_attn.k_proj\n",
      "pruning layer 18 name self_attn.v_proj\n",
      "pruning layer 18 name self_attn.o_proj\n",
      "pruning layer 18 name mlp.gate_proj\n",
      "pruning layer 18 name mlp.up_proj\n",
      "pruning layer 18 name mlp.down_proj\n",
      "pruning layer 19 name self_attn.q_proj\n",
      "pruning layer 19 name self_attn.k_proj\n",
      "pruning layer 19 name self_attn.v_proj\n",
      "pruning layer 19 name self_attn.o_proj\n",
      "pruning layer 19 name mlp.gate_proj\n",
      "pruning layer 19 name mlp.up_proj\n",
      "pruning layer 19 name mlp.down_proj\n",
      "pruning layer 20 name self_attn.q_proj\n",
      "pruning layer 20 name self_attn.k_proj\n",
      "pruning layer 20 name self_attn.v_proj\n",
      "pruning layer 20 name self_attn.o_proj\n",
      "pruning layer 20 name mlp.gate_proj\n",
      "pruning layer 20 name mlp.up_proj\n",
      "pruning layer 20 name mlp.down_proj\n",
      "pruning layer 21 name self_attn.q_proj\n",
      "pruning layer 21 name self_attn.k_proj\n",
      "pruning layer 21 name self_attn.v_proj\n",
      "pruning layer 21 name self_attn.o_proj\n",
      "pruning layer 21 name mlp.gate_proj\n",
      "pruning layer 21 name mlp.up_proj\n",
      "pruning layer 21 name mlp.down_proj\n",
      "pruning layer 22 name self_attn.q_proj\n",
      "pruning layer 22 name self_attn.k_proj\n",
      "pruning layer 22 name self_attn.v_proj\n",
      "pruning layer 22 name self_attn.o_proj\n",
      "pruning layer 22 name mlp.gate_proj\n",
      "pruning layer 22 name mlp.up_proj\n",
      "pruning layer 22 name mlp.down_proj\n",
      "pruning layer 23 name self_attn.q_proj\n",
      "pruning layer 23 name self_attn.k_proj\n",
      "pruning layer 23 name self_attn.v_proj\n",
      "pruning layer 23 name self_attn.o_proj\n",
      "pruning layer 23 name mlp.gate_proj\n",
      "pruning layer 23 name mlp.up_proj\n",
      "pruning layer 23 name mlp.down_proj\n",
      "pruning layer 24 name self_attn.q_proj\n",
      "pruning layer 24 name self_attn.k_proj\n",
      "pruning layer 24 name self_attn.v_proj\n",
      "pruning layer 24 name self_attn.o_proj\n",
      "pruning layer 24 name mlp.gate_proj\n",
      "pruning layer 24 name mlp.up_proj\n",
      "pruning layer 24 name mlp.down_proj\n",
      "pruning layer 25 name self_attn.q_proj\n",
      "pruning layer 25 name self_attn.k_proj\n",
      "pruning layer 25 name self_attn.v_proj\n",
      "pruning layer 25 name self_attn.o_proj\n",
      "pruning layer 25 name mlp.gate_proj\n",
      "pruning layer 25 name mlp.up_proj\n",
      "pruning layer 25 name mlp.down_proj\n",
      "pruning layer 26 name self_attn.q_proj\n",
      "pruning layer 26 name self_attn.k_proj\n",
      "pruning layer 26 name self_attn.v_proj\n",
      "pruning layer 26 name self_attn.o_proj\n",
      "pruning layer 26 name mlp.gate_proj\n",
      "pruning layer 26 name mlp.up_proj\n",
      "pruning layer 26 name mlp.down_proj\n",
      "pruning layer 27 name self_attn.q_proj\n",
      "pruning layer 27 name self_attn.k_proj\n",
      "pruning layer 27 name self_attn.v_proj\n",
      "pruning layer 27 name self_attn.o_proj\n",
      "pruning layer 27 name mlp.gate_proj\n",
      "pruning layer 27 name mlp.up_proj\n",
      "pruning layer 27 name mlp.down_proj\n",
      "pruning layer 28 name self_attn.q_proj\n",
      "pruning layer 28 name self_attn.k_proj\n",
      "pruning layer 28 name self_attn.v_proj\n",
      "pruning layer 28 name self_attn.o_proj\n",
      "pruning layer 28 name mlp.gate_proj\n",
      "pruning layer 28 name mlp.up_proj\n",
      "pruning layer 28 name mlp.down_proj\n",
      "pruning layer 29 name self_attn.q_proj\n",
      "pruning layer 29 name self_attn.k_proj\n",
      "pruning layer 29 name self_attn.v_proj\n",
      "pruning layer 29 name self_attn.o_proj\n",
      "pruning layer 29 name mlp.gate_proj\n",
      "pruning layer 29 name mlp.up_proj\n",
      "pruning layer 29 name mlp.down_proj\n",
      "pruning layer 30 name self_attn.q_proj\n",
      "pruning layer 30 name self_attn.k_proj\n",
      "pruning layer 30 name self_attn.v_proj\n",
      "pruning layer 30 name self_attn.o_proj\n",
      "pruning layer 30 name mlp.gate_proj\n",
      "pruning layer 30 name mlp.up_proj\n",
      "pruning layer 30 name mlp.down_proj\n",
      "pruning layer 31 name self_attn.q_proj\n",
      "pruning layer 31 name self_attn.k_proj\n",
      "pruning layer 31 name self_attn.v_proj\n",
      "pruning layer 31 name self_attn.o_proj\n",
      "pruning layer 31 name mlp.gate_proj\n",
      "pruning layer 31 name mlp.up_proj\n",
      "pruning layer 31 name mlp.down_proj\n",
      "layer 0 sparsity 0.500000\n",
      "layer 1 sparsity 0.500000\n",
      "layer 2 sparsity 0.500000\n",
      "layer 3 sparsity 0.500000\n",
      "layer 4 sparsity 0.500000\n",
      "layer 5 sparsity 0.500000\n",
      "layer 6 sparsity 0.500000\n",
      "layer 7 sparsity 0.500000\n",
      "layer 8 sparsity 0.500000\n",
      "layer 9 sparsity 0.500000\n",
      "layer 10 sparsity 0.500000\n",
      "layer 11 sparsity 0.500000\n",
      "layer 12 sparsity 0.500000\n",
      "layer 13 sparsity 0.500000\n",
      "layer 14 sparsity 0.500000\n",
      "layer 15 sparsity 0.500000\n",
      "layer 16 sparsity 0.500000\n",
      "layer 17 sparsity 0.500000\n",
      "layer 18 sparsity 0.500000\n",
      "layer 19 sparsity 0.500000\n",
      "layer 20 sparsity 0.500000\n",
      "layer 21 sparsity 0.500000\n",
      "layer 22 sparsity 0.500000\n",
      "layer 23 sparsity 0.500000\n",
      "layer 24 sparsity 0.500000\n",
      "layer 25 sparsity 0.500000\n",
      "layer 26 sparsity 0.500000\n",
      "layer 27 sparsity 0.500000\n",
      "layer 28 sparsity 0.500000\n",
      "layer 29 sparsity 0.500000\n",
      "layer 30 sparsity 0.500000\n",
      "layer 31 sparsity 0.500000\n",
      "å®žé™… sparsity: 0.500000\n",
      "evaluating on wikitext\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aec409326304a6386fac16386533284",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae6e4bcc4d2543229c0e5bec92fa7da7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94e651c6c0d54e168d6238f2618e0294",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/733k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dd484fa95d44c549754d9072590c6c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/6.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35e4dfc96ca34afb9674789f75c4228b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/657k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "701834ada6824f9d8ee645975713e285",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "994d2ba897df4398bd7b1271c0982740",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/4358 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cc2450a8e044f82a49368f044fa6401",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/36718 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1cad852f667486a963203093b377d42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/3760 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nsamples 83\n",
      "sample 0\n",
      "sample 50\n",
      "Perplexity (Wikitext): 8.0701\n"
     ]
    }
   ],
   "source": [
    "# tokenizer\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    modeltype2path[model_name],\n",
    "    use_fast=False,\n",
    "    cache_dir=cache_dir,\n",
    ")\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({\"pad_token\": \"[PAD]\"})\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# âœ… Pruning (ä»… unstructured çš„ wanda æ–¹æ³•)\n",
    "prune_n, prune_m = 0, 0\n",
    "print(\"å¼€å§‹å‰ªæžï¼š\", prune_method)\n",
    "prune_wanda(\n",
    "    args=args,  # ä¸ç”¨ args\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    model_base=model_base,  \n",
    "    device=device,\n",
    "    prune_n=prune_n,\n",
    "    prune_m=prune_m,\n",
    "    prune_data=args.prune_data,\n",
    ")\n",
    "\n",
    "# âœ… Sparsity æ£€æŸ¥\n",
    "sparsity_ratio_actual = check_sparsity(model)\n",
    "print(f\"å®žé™… sparsity: {sparsity_ratio_actual:.6f}\")\n",
    "\n",
    "# âœ… PPL è¯„ä¼°\n",
    "ppl = eval_ppl(\n",
    "    args=None,\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    device=device,\n",
    ")\n",
    "print(f\"Perplexity (Wikitext): {ppl:.4f}\")\n",
    "\n",
    "# âœ… é€‰æ‹©æ€§ä¿å­˜ maskï¼ˆå¯é€‰ï¼‰\n",
    "save_mask_flag = False\n",
    "if save_mask_flag:\n",
    "    mask = get_mask(model, neg_prune)\n",
    "    mask_dir = os.path.join(save_dir, \"FT_mask\")\n",
    "    os.makedirs(mask_dir, exist_ok=True)\n",
    "    mask_path = os.path.join(mask_dir, f\"mask_bottom_{sparsity_ratio:.3f}.pt\")\n",
    "    torch.save(mask, mask_path)\n",
    "    print(f\"Mask å·²ä¿å­˜: {mask_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ec4dd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prune_llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
